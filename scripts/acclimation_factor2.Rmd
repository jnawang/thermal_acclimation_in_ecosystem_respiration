---
title: "acclimation_factors"
output: pdf_document
date: "2024-04-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(terra)
library(ggpubr)
#
```


##get climate class
```{r how to obtain climate class, only use once}
rm(list=ls())
#
acclimation <- read.csv('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/basic_site_info.csv')
#
climate.koppen <- terra::rast('/Users/jw2946/Documents/stability_project/global_data/koppen_geiger/1991_2020/koppen_geiger_0p00833333.tif')
#
plot(climate.koppen)
# get climate for these coordination
#
xy <- data.frame(x=acclimation$LONG, y=acclimation$LAT)
#
tmp <- terra::extract(climate.koppen, xy)
# if_else(), case_when()
#
tmp <- tmp %>% mutate(koppen = case_when(
  koppen_geiger_0p00833333 == 25 ~ 'Dfa',  
  koppen_geiger_0p00833333 == 26 ~ 'Dfb', 
  koppen_geiger_0p00833333 == 27 ~ 'Dfc',  
  koppen_geiger_0p00833333 == 9  ~ 'Csb', 
  koppen_geiger_0p00833333 == 8  ~ 'Csa',
  koppen_geiger_0p00833333 == 7  ~ 'BSk',
  koppen_geiger_0p00833333 == 6  ~ 'BSh',
  koppen_geiger_0p00833333 == 5  ~ 'BWk',  
  koppen_geiger_0p00833333 == 4  ~ 'BWh',
  koppen_geiger_0p00833333 == 2  ~ 'Am',
  koppen_geiger_0p00833333 == 18  ~ 'Dsb',
  koppen_geiger_0p00833333 == 14  ~ 'Cfa',
  koppen_geiger_0p00833333 == 15  ~ 'Cfb'
#
))
tmp$site_ID <- acclimation$site_ID
tmp$climate.flux <- acclimation$Climate_class
#
# perhaps 8 and 9 can be merged as 'Mediterrean Climate'
# 4, 5, 6, and 7 can be merged
# 25, 26, 27; cold and wet climate
# 14, 15 can be merged. 

# we do have tropical rainforests. 

```

##get soil properties
```{r get soil property data from global dataset, used only once}
library(geodata)
library(terra)
#
rm(list=ls())
#
acclimation <- read.csv('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/basic_site_info.csv')
#
stat.soil <- data.frame(site_ID=acclimation$site_ID)
#
GSOCmap <- terra::rast('/Users/jw2946/Documents/stability_project/global_data/soil/GSOCmap1.5.0.tif')
plot(GSOCmap)
#
xy <- data.frame(x=acclimation$LONG, y=acclimation$LAT)
#
stat.soil$GSOC <- terra::extract(GSOCmap, xy)$GSOCmap1.5.0
# Annual mean of the 1970~2000 period, aridicity index
AImap  <- terra::rast('/Users/jw2946/Documents/stability_project/global_data/soil/Global-AI_ET0_v3_annual/ai_v3_yr.tif')
#
stat.soil$AI <- terra::extract(AImap, xy)$awi_pm_sr_yr / 10000  # conversion of data
#
# 
files   <- list.files('/Users/jw2946/Documents/stability_project/global_data/soil/soil_world/', full.names = T)
SOILmap <- terra::rast(files)
tmp <- terra::extract(SOILmap, xy)
stat.soil$bdod     <- (tmp[,1] + tmp[,2]) / 2      # the average of the top 15 cm;
# stat.soil$clay     <- (tmp[,3] + tmp[,4]) / 2    # some thing wrong with the clay layer; 
stat.soil$nitrogen <- (tmp[,5] + tmp[,6]) / 2
stat.soil$phh2o    <- (tmp[,7] + tmp[,8]) / 2
stat.soil$sand     <- (tmp[,9] + tmp[,10]) / 2
stat.soil$silt     <- (tmp[,11] + tmp[,12]) / 2
stat.soil$soc      <- (tmp[,13] + tmp[,14]) / 2
stat.soil$clay     <- 100 - stat.soil$sand - stat.soil$silt
# I do not know how much I can trust this data, soc and GSOC are not correlated. 

# deal with soil microbial data, this will be correlated to SOC?
microbe <- terra::rast('/Users/jw2946/Documents/stability_project/global_data/soil/Global_Soil_Microbial_BiomassCN.nc')
plot(microbe)
# change xy of the 2 and 18 rows because they are too close to water. 
xy2 <- xy
xy2[2,]  <- xy[2,] - 0.05
xy2[18,] <- xy[18,] - 0.06
tmp <- terra::extract(microbe, xy2)
tmp[abs(tmp+9999) < 0.1] <- NA
stat.soil$SMC30cm <- tmp$SMC30cm
stat.soil$SMN30cm <- tmp$SMN30cm
stat.soil$CN30cm  <- tmp$CN30cm
#
stat.soil$SMC100cm <- tmp$SMC100cm
stat.soil$SMN100cm <- tmp$SMN100cm
#
# BADM files for Ameriflux sites
BIF <- read.csv('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/AMF_AA-Net_BIF_LEGACY_20240930.csv')
BIF.site <- BIF %>% filter(SITE_ID %in% acclimation$site_ID) %>% filter(VARIABLE=='SOIL_CHEM_C_ORG') %>% group_by(SITE_ID) %>% summarise(soc_obs = mean(as.numeric(DATAVALUE), na.rm=T))     # 25 sites
# BIF.site.bd <- BIF %>% filter(SITE_ID %in% acclimation$site_ID) %>% filter(VARIABLE=='SOIL_CHEM_BD') %>% group_by(SITE_ID) %>% summarise(bd_obs = mean(as.numeric(DATAVALUE), na.rm=T))     # 27 sites
# BIF.site <- BIF.site %>% left_join(BIF.site.bd, by='SITE_ID')  # it is even worse when considering bulk density!
#
# Compare these field data with map data, why I did not think of this method?
tmp <- BIF.site %>% left_join(stat.soil, by=c('SITE_ID'='site_ID'))        # I have to use GSOC, soc data is unreliable at all. 
cor.test(tmp$soc_obs, tmp$GSOC)  # p-value = 0.026, r = 0.446
# I need to do some corrections for GSOC
model <- lm(data=tmp, GSOC ~ soc_obs)
BIF.site$GSOC_obs <- predict(model, tmp[c("soc_obs")])

#
# the unit of the BIF data set is g C kg soil-1
BIF.site.n <- BIF %>% filter(SITE_ID %in% acclimation$site_ID) %>% filter(VARIABLE=='SOIL_CHEM_N_TOT') %>% group_by(SITE_ID) %>% summarise(sn_obs = mean(as.numeric(DATAVALUE), na.rm=T))     # 17 sites
#
tmp <- BIF.site.n %>% left_join(stat.soil, by=c('SITE_ID'='site_ID'))
cor.test(tmp$sn_obs, tmp$nitrogen)  # p-value = 0.9594, r = 0.01336958
#
# pH values measured by salt, such as CaCl2
BIF.site.ph <- BIF %>% filter(SITE_ID %in% acclimation$site_ID) %>% filter(VARIABLE=='SOIL_CHEM_PH_SALT') %>% group_by(SITE_ID) %>% summarise(ph_obs = mean(as.numeric(DATAVALUE), na.rm=T))     # 18 sites
BIF.site.ph$ph_obs <- BIF.site.ph$ph_obs + 0.6
#
BIF.site.ph.h2o <- BIF %>% filter(SITE_ID %in% acclimation$site_ID) %>% filter(VARIABLE=='SOIL_CHEM_PH_H2O') %>% group_by(SITE_ID) %>% summarise(ph_obs = mean(as.numeric(DATAVALUE), na.rm=T))     # 1 sites
# merge the two frame together
BIF.site.ph <- rbind(BIF.site.ph, BIF.site.ph.h2o)
#
tmp <- BIF.site.ph %>% left_join(stat.soil, by=c('SITE_ID'='site_ID'))  
cor.test(tmp$ph_obs, tmp$phh2o)  # p-value = 0.8078, r = 0.05982185; I should not use this data; this is ridicuous! 
#
# combine the two variables into soil data
stat.soil <- stat.soil %>% left_join(BIF.site, by=c('site_ID'='SITE_ID')) %>% left_join(BIF.site.n, by=c('site_ID'='SITE_ID')) %>% left_join(BIF.site.ph, by=c('site_ID'='SITE_ID')) 
#
write.csv(stat.soil, file='/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/soil.csv', row.names=FALSE)
# read global soil carbon data; this may be not helpful, because it is total carbon 
# totc <- terra::vect('/Users/jw2946/Downloads/wosis_latest.shp')
# plot(totc)
#
```

##get climate properties; use site specific data (double check correlation)
```{r calculate climatic variables, used only once}
library(zoo)
library(lubridate)
library(tidyverse)
#
# calculate the following variables
# mean annual NEE, mean annual GPP, and mean annual night NEE [I have to differentiate daytime and nighttime].
stat.climate <- data.frame(site_ID=character(), NEE=double(), NEE_day=double(), NEE_night=double(),                      
                           MATA=double(), SSTA=double(), IATA=double(), RDTA=double(), RSTA=double(),
                           MATS=double(), SSTS=double(), IATS=double(), RDTS=double(), RSTS=double(),
                           NEE2=double(), NEE_day2=double(), NEE_night2=double(),
                           NEE_FLUXNET=double(), MAT_FLUXNET=double(), P_FLUXNET=double())
# notation of variable names
# MA: mean annual; SS: seasonal variation; IA: inter-annual variation; RD: daily range; RS: seasonal range
#
# Read ac data
data.dir <- '/Users/jw2946/Documents/stability_project/RespiarationData/ALL10122024/'
files <- list.files(data.dir, pattern = '_ac.RDS$', full.names = TRUE)
for (i in 1:length(files)) {
#  i = 60
  name_site <- substring(files[i], nchar(files[i])-12, nchar(files[i])-7)
  print(paste0(i, name_site))
  stat.climate[i, 1] <- name_site        # the last value
  ac <- readRDS(files[i])
  # use only the years with qualified data
  outcome <- readRDS(paste0(data.dir, name_site, '_outcome.RDS'))
  good_years <- as.integer(colnames(outcome$result)[!is.na(outcome$result[1,])])
  good_years <- good_years[!is.na(good_years)]
  # I have to gap fill TA, TS, and NEE, if needed.
  if (!"TA_gf" %in% colnames(ac)) {
    T_gf <- ac %>% group_by(DOY, HOUR, MINUTE) %>% summarise(TA_gf=mean(TA, na.rm=T), TS_gf=mean(TS, na.rm=T), NEE_gf=mean(NEE, na.rm=T))  # for gap fill only.    
    ac   <- ac %>% left_join(T_gf, by=c("DOY", "HOUR", "MINUTE"))
    #
    # I still need a standard gap-fill methods. 
    if (sum(is.na(ac$TA)) > 0) {
      ac$TA[is.na(ac$TA)] <- ac$TA_gf[is.na(ac$TA)]
    }
    if (sum(is.na(ac$TS)) > 0) {
      ac$TS[is.na(ac$TS)] <- ac$TS_gf[is.na(ac$TS)]
    }
    if (sum(is.na(ac$NEE)) > 0) {
      ac$NEE[is.na(ac$NEE)] <- ac$NEE_gf[is.na(ac$NEE)]
    } 
  }
  #
  # Do NEE separately
  # only use the selected years data; find good years from other datasets!
  # use interpolated values
  annual <- ac %>% filter(YEAR %in% good_years) %>% group_by(YEAR) %>% summarise(NEE=sum(NEE_uStar_f, na.rm=T))
  annual_day   <- ac %>% filter(YEAR %in% good_years & daytime) %>% group_by(YEAR) %>% summarise(NEE=sum(NEE_uStar_f, na.rm=T))
  annual_night <- ac %>% filter(YEAR %in% good_years & !daytime) %>% group_by(YEAR) %>% summarise(NEE=sum(NEE_uStar_f, na.rm=T))
  # get time interval
  # dt <- as.numeric(ac$TIMESTAMP[2] - ac$TIMESTAMP[1])     this is a wrong way!
  dt <- abs(ac$MINUTE[2] + ac$HOUR[2] * 60 - ac$MINUTE[1] - ac$HOUR[1] * 60)
  #  
  ######alternative methods
  stat.climate[i, 2] <- mean(annual$NEE) * dt * 60 / 1000000 * 12        ### g C / m2;
  stat.climate[i, 3] <- mean(annual_day$NEE) * dt * 60 / 1000000 * 12    ### g C / m2;
  stat.climate[i, 4] <- mean(annual_night$NEE) * dt * 60 / 1000000 * 12  ### g C / m2;
  #
  # I have to interpolate missing values
  data_yearly  <- ac %>% filter(YEAR %in% good_years) %>% group_by(DOY, HOUR, MINUTE, daytime) %>% summarise(NEE=mean(NEE, na.rm=T))
  # remove duplicate rows
  data_yearly  <- data_yearly[!duplicated(data_yearly[,c('DOY', 'HOUR', 'MINUTE')]), ]
  #
  data_yearly$time <- data_yearly$DOY + data_yearly$HOUR / 24 + data_yearly$MINUTE / 60 / 24
  # re-order the data
  data_yearly <- data_yearly %>% arrange(time)
  # then linear interpolation
  data_yearly$NEE.appr <- na.approx(data_yearly$NEE, data_yearly$time, na.rm = FALSE)
  # dealing with missing head and end data
  num_min <- min(which(!is.na(data_yearly$NEE.appr)))
  num_max <- max(which(!is.na(data_yearly$NEE.appr)))
  if (num_min > 1) {
    data_yearly$NEE.appr[1:(num_min-1)] <- data_yearly$NEE.appr[num_min]
  }
  if (num_max < nrow(data_yearly)) {
    data_yearly$NEE.appr[(num_max+1):nrow(data_yearly)] <- data_yearly$NEE.appr[num_max]
  } 
  # then sum
  stat.climate[i, 15] <- sum(data_yearly$NEE.appr) * dt * 60 / 1000000 * 12  ### g CO2 / m2  
  stat.climate[i, 16] <- sum(data_yearly$NEE.appr[data_yearly$daytime], na.rm=T) * dt * 60 / 1000000 * 12  ### g CO2 / m2; na.rm for tundra sites
  stat.climate[i, 17] <- sum(data_yearly$NEE.appr[!data_yearly$daytime], na.rm=T) * dt * 60 / 1000000 * 12  ### g CO2 / m2
  ##############################air temperature and soil temperature############################
  data_yearly  <- ac %>% filter(YEAR %in% good_years) %>% group_by(DOY) %>% summarise(TS=mean(TS, na.rm=T), TA=mean(TA, na.rm=T))
  # Mean annual
  stat.climate[i, 5] <- mean(data_yearly$TA)
  stat.climate[i, 10] <- mean(data_yearly$TS)
  #
  # Seasonal variations
  data_1day      <- ac %>% filter(YEAR %in% good_years) %>% group_by(YEAR, DOY) %>% summarise(TSrange=max(TS, na.rm=T)-min(TS, na.rm=T), TArange=max(TA, na.rm=T)-min(TA, na.rm=T), TS=mean(TS, na.rm=T), TA=mean(TA, na.rm=T))
  data_1year_sd  <- data_1day %>% group_by(YEAR) %>% summarise(TS=sd(TS, na.rm=T), TA=sd(TA, na.rm=T))
  stat.climate[i, 6]  <- mean(data_1year_sd$TA)
  stat.climate[i, 11] <- mean(data_1year_sd$TS)
  #
  # Inter-annual variations
  data_1year_mn  <- data_1day %>% group_by(YEAR) %>% summarise(TS=mean(TS, na.rm=T), TA=mean(TA, na.rm=T))
  stat.climate[i, 7]  <- sd(data_1year_mn$TA)
  stat.climate[i, 12] <- sd(data_1year_mn$TS)
  # Daily range
  stat.climate[i, 8]   <- mean(data_1day$TArange)
  stat.climate[i, 13]  <- mean(data_1day$TSrange, na.rm=T)
  # Seasonal range
  data_1year_rg  <- data_1day %>% group_by(YEAR) %>% summarise(TS=max(TS, na.rm=T)-min(TS, na.rm=T),                                                                                                       TA=max(TA, na.rm=T)-min(TA, na.rm=T))
  stat.climate[i, 9]  <- mean(data_1year_rg$TA)
  stat.climate[i, 14] <- mean(data_1year_rg$TS)
  #####get ecosystem properties for sites in FLUXNET2020; double check these values; get the annual sheet and calculate the average values.
  path    <- '/Users/jw2946/Documents/stability_project/SiteData/FLUXNET2020/'
  pattern <- paste0('FLX_', name_site, '_FLUXNET2015_FULLSET')
  #
  files.fluxnet2020  <- list.files(path=path, pattern = pattern, full.names = TRUE)
  if (length(files.fluxnet2020) > 0) {                  # the site is in the dataset
    file   <- files.fluxnet2020[grepl(name_site, files.fluxnet2020)]
    files.in  <- unzip(file, list=TRUE)
    #
    pattern <- paste0('FLX_', name_site, '_FLUXNET2015_FULLSET_YY_')
    #
    exdir <- paste0(path, 'unzip/')
    file.in   <- files.in$Name[grepl(pattern, files.in$Name)]
    unzip(file, files=file.in, exdir=exdir)
    a_annual <- read.csv(file.path(exdir, file.in))
    a_annual[abs(a_annual+9999) < 0.1] <- NA
    stat.climate[i, 18] = mean(a_annual$NEE_VUT_REF, na.rm=T)
    # stat.climate[i, 19] = mean(a_annual$NEE_VUT_REF_DAY, na.rm=T)
    # stat.climate[i, 20] = mean(a_annual$NEE_VUT_REF_NIGHT, na.rm=T)
    stat.climate[i, 19] = mean(a_annual$TA_F_MDS, na.rm=T)
    stat.climate[i, 20] = mean(a_annual$P_F, na.rm=T)
  }
}

# correlation of these climatic variables?
cor(stat.climate[, 2:17])
#
write.csv(stat.climate, file='/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/climate.csv', row.names=FALSE)
#
```

```{r dirty climateR}
# get MAT and P from climate R; this is US only data!
# library(climateR)
# library(AOI)
# library(sf)
# #
# # Define the coordinates and time range
# coords <- data.frame(long=basic$LONG, lat=basic$LAT)
# sf_points <- st_as_sf(coords, coords = c("long", "lat"), crs = 4326)
# # plot(sf_points)
# start_date <- "2000-01-01"  # Start date
# end_date   <- "2000-12-31"    # End date
# 
# # Download the climate data; this returns a map!!!!
# climate_data <- getGridMET(AOI = sf_points, 
#                            varname = "pr", 
#                            startDate = start_date, 
#                            endDate = end_date)
```

##get spectral information
```{r get LAI and NDVI}
library(corrplot)
#
data.dir <- '/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/spectral_information_tower_sites'
file1    <- read.csv(file.path(data.dir, 'towers-MOD13A2-061-results.csv'))  ##EVI and NDVI
# remove nonsense results
file1$MOD13A2_061__1_km_16_days_EVI[file1$MOD13A2_061__1_km_16_days_EVI < 0]  <- NA
file1$MOD13A2_061__1_km_16_days_NDVI[file1$MOD13A2_061__1_km_16_days_NDVI < 0]  <- NA
file1$Date <- as.Date(file1$Date)
#
IDs <- unique(file1$ID)
for (id in IDs) {
  print(id)
  data.site <- file1 %>% filter(ID == id)
  p <- ggplot(data = data.site, aes(x=Date, y=MOD13A2_061__1_km_16_days_NDVI)) +
    geom_point() +
    labs(title = id)
  plot(p)
}
#######
file2    <- read.csv(file.path(data.dir, 'towers-MOD15A2H-061-results.csv'))  ##Fpar and LAI
# remove nonsense results
file2$MOD15A2H_061_Fpar_500m[file2$MOD15A2H_061_Fpar_500m > 100]  <- NA
file2$MOD15A2H_061_Lai_500m[file2$MOD15A2H_061_Lai_500m > 100]  <- NA
file2$Date <- as.Date(file2$Date)
#
IDs <- unique(file2$ID)
for (id in IDs) {
  print(id)
  id ='US-GLE'
  data.site <- file2 %>% filter(ID == id)
  p <- ggplot(data = data.site, aes(x=Date, y=MOD15A2H_061_Lai_500m)) +
    geom_point() +
    labs(title = id)
  plot(p)
}
#####
file3      <- read.csv(file.path(data.dir, 'towers-MYD17A2HGF-061-results.csv'))  ##GPP
# remove nonsense results; no need!
# file3$MYD17A2HGF_061_Gpp_500m[file3$MYD17A2HGF_061_Gpp_500m]
file3$Date <- as.Date(file3$Date)
#
IDs <- unique(file3$ID)
for (id in IDs) {
  print(id)
  # id ='US-GLE'
  data.site <- file3 %>% filter(ID == id)
  p <- ggplot(data = data.site, aes(x=Date, y=MYD17A2HGF_061_Gpp_500m)) +
    geom_point() +
    labs(title = id)
  plot(p)
}

# site average data: vegetation index
VI <- file1 %>% group_by(ID) %>% summarise(EVI=mean(MOD13A2_061__1_km_16_days_EVI, na.rm=T), NDVI=mean(MOD13A2_061__1_km_16_days_NDVI, na.rm=T)) 
# LAI: unitless
LAI <- file2 %>% group_by(ID) %>% summarise(Fpar=mean(MOD15A2H_061_Fpar_500m, na.rm=T), Lai=mean(MOD15A2H_061_Lai_500m, na.rm=T)) 
# GPP: kgC/m2/8d -> convert to kgC/m2/year
GPP <- file3 %>% group_by(ID) %>% summarise(Gpp=mean(MYD17A2HGF_061_Gpp_500m, na.rm=T)/8*365.25) 
data.spectral <- VI %>% left_join(LAI, by='ID') %>% left_join(GPP, by="ID")
# site year average data

#### the correlations between GPP, LAI, EVI, and NDVI of these sites; need to take a look at this first!  
data.spectral.tower <- data.spectral %>% left_join(stat.climate, by=c("ID"="site_ID" ))
corrplot(cor(data.spectral.tower[, 2:9]),
  method = "number",
  sig.level = 0.05,
  type = "upper" # show only upper side
)
# LAI, GPP are strongly related to NEE_day; try to use this. 
write.csv(data.spectral, file='/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/spectral.csv', row.names=FALSE)

```

##recalculate thermal acclimation strength, need to merge all the sites
```{r unified method to calculate acclimation in growing season}
rm(list=ls())
options(na.action = na.omit)
acclimation.strength <- data.frame(site_ID=character(), nyear=integer(), strgth=double(), strgth_p=double(), 
                                   r3=double(), r3_p=double(), r3avg=double(), r3avg_p=double(),
                                   r3avg05=double(), r3avg95=double(), dTS_gs=double(), SWC_use=character()) # , r3avg0=double(), r3avg0_p=double()
data_dir <- "/Users/jw2946/Documents/stability_project/RespiarationData/ALL10122024/"
files <- list.files(data_dir, pattern='_outcome.RDS', full.names = T) 
files_nowater <- list.files(data_dir, pattern='_outcome_nowater.RDS', full.names = F) 
for (i in 1:length(files)) {
#  i = 90
  print(i)
  outcome.in <- readRDS(files[i])
  #
  acclimation.strength[i, 1] <- outcome.in$site_ID
  tStart   <- outcome.in$tStart
  tEnd     <- outcome.in$tEnd
  NEE_grow <- outcome.in$NEE_grow
  nyear    <- nrow(NEE_grow)
  #
  # average respiration over the growing season
  result_row <- outcome.in$result
  Ravg_GW    <- colSums(result_row[tStart:tEnd, 2:(nyear+1)]) * 0.1
  Ravg_GW    <- Ravg_GW / mean(Ravg_GW, na.rm=T) 
  #
  # average response ratio over the growing season
  result_row_avg <- rowMeans(result_row[, 2:(nyear+1)], na.rm=T)
  RRavg_GW       <- log(result_row[tStart:tEnd, 2:(nyear+1)] / result_row_avg[tStart:tEnd])
  # one way is to directly average
#  RRavg_GW       <- colMeans(RRavg_GW)
  #
  # what if I use weighted average for each column/year
  RRavg_GW       <- (RRavg_GW * result_row_avg[tStart:tEnd]) / sum(result_row_avg[tStart:tEnd])
  RRavg_GW       <- colSums(RRavg_GW)
  #
  # number of years data
  acclimation.strength[i, 2] <- sum(!is.na(Ravg_GW))
  #
  # calculate acclimation strength by three methods
  df <- data.frame(TS=NEE_grow$TS, SWC=NEE_grow$SWC, alpha=Ravg_GW, alpha_ln=log(Ravg_GW), alpha_ln_avg=RRavg_GW)
  plot <- ggplot(df, aes(x=TS, y=alpha_ln_avg)) + 
  geom_point() +
  geom_smooth(method = lm) +
  stat_cor(color='green') +
  labs(x='Mean soil temperature (C)', y='Respiration response ratio')
  print(plot)
  #
  # if (outcome.in$site_ID %in% c('US-Wkg', 'US-Whs', 'US-SRM')) {
  #   acclimation.strength[i, 3:4] <- summary(lm(data=df, alpha~TS+SWC))$coefficients[2,c(1,4)]
  #   #
  #   acclimation.strength[i, 5:6] <- summary(lm(data=df, alpha_ln~TS+SWC))$coefficients[2,c(1,4)]
  #   #
  #   acclimation.strength[i, 7:8] <- summary(lm(data=df, alpha_ln_avg~TS+SWC))$coefficients[2,c(1,4)]    
  # } else {
    acclimation.strength[i, 3:4] <- summary(lm(data=df, alpha~TS))$coefficients[2,c(1,4)]
    #
    acclimation.strength[i, 5:6] <- summary(lm(data=df, alpha_ln~TS))$coefficients[2,c(1,4)]
    #
    acclimation.strength[i, 7:8] <- summary(lm(data=df, alpha_ln_avg~TS))$coefficients[2,c(1,4)]    
  # }
    #
#    acclimation.strength[i, 8:9] <- summary(lm(data=df, alpha_ln_avg~TS))$coefficients[2,c(1,4)]  
    # confidence interval of the slope
    acclimation.strength[i, 9:10] <- confint(lm(data=df, alpha_ln_avg~TS), "TS", level=0.9)[1:2]
    acclimation.strength[i, 11]   <- max(NEE_grow$TS, na.rm=T) - min(NEE_grow$TS, na.rm=T)
    #
    if (paste0(outcome.in$site_ID, '_outcome_nowater.RDS') %in% files_nowater) {
      acclimation.strength[i, 12] <- 'YES'
    } else {
      acclimation.strength[i, 12] <- 'NO'
    }
}

# these strengths are highly correlated
write.csv(acclimation.strength, file='/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/acclimation_strength.csv', row.names=FALSE)
# overall, we have 23 site with p < 0.05; 30%
# we have 31 sites with p < 0.1 and compensating acclimation; 40 % (31/76)
# we have 17 sites with positive acclimation strength: 18 %; none of the compensating thermal acclimation is significant.
#
```


```{r unified method to calculate acclimation but no water}
# rm(list=ls())
options(na.action = na.omit)
acclimation.strength.nowater <- data.frame(site_ID=character(), strgth=double(), strgth_p=double(), 
                                   r3=double(), r3_p=double(), r3avg=double(), r3avg_p=double()) # , r3avg0=double(), r3avg0_p=double()
data_dir <- "/Users/jw2946/Documents/stability_project/RespiarationData/ALL10122024/"
files <- list.files(data_dir, pattern='_outcome_nowater.RDS', full.names = T) 
for (i in 1:length(files)) {
#  i = 1
  print(i)
  outcome.in <- readRDS(files[i])
  #
  acclimation.strength.nowater[i, 1] <- outcome.in$site_ID
  tStart   <- outcome.in$tStart
  tEnd     <- outcome.in$tEnd
  NEE_grow <- outcome.in$NEE_grow
  nyear    <- nrow(NEE_grow)
  #
  # average respiration over the growing season
  result_row <- outcome.in$result
  Ravg_GW    <- colSums(result_row[tStart:tEnd, 2:(nyear+1)]) * 0.1
  Ravg_GW    <- Ravg_GW / mean(Ravg_GW, na.rm=T) 
  #
  # average response ratio over the growing season
  result_row_avg <- rowMeans(result_row[, 2:(nyear+1)], na.rm=T)
  RRavg_GW       <- log(result_row[tStart:tEnd, 2:(nyear+1)] / result_row_avg[tStart:tEnd])
  # one way is to directly average
#  RRavg_GW       <- colMeans(RRavg_GW)
  #
  # what if I use weighted average for each column/year
  RRavg_GW       <- (RRavg_GW * result_row_avg[tStart:tEnd]) / sum(result_row_avg[tStart:tEnd])
  RRavg_GW       <- colSums(RRavg_GW)
  #
  # calculate acclimation strength by three methods
  df <- data.frame(TS=NEE_grow$TS, SWC=NEE_grow$SWC, alpha=Ravg_GW, alpha_ln=log(Ravg_GW), alpha_ln_avg=RRavg_GW)
  ggplot(df, aes(x=TS, y=alpha_ln)) + 
  geom_point() +
  geom_smooth(method = lm) +
  stat_cor(color='green') +
  labs(x='Mean soil temperature (C)', y='Respiration response ratio')
  acclimation.strength.nowater[i, 2:3] <- summary(lm(data=df, alpha~TS))$coefficients[2,c(1,4)]
  #
  acclimation.strength.nowater[i, 4:5] <- summary(lm(data=df, alpha_ln~TS))$coefficients[2,c(1,4)]
  #
  acclimation.strength.nowater[i, 6:7] <- summary(lm(data=df, alpha_ln_avg~TS))$coefficients[2,c(1,4)]    
}
#
colnames(acclimation.strength.nowater)[2:7] <- paste0(colnames(acclimation.strength.nowater)[2:7], '_nw')
# left_join with other variables
acclimation.strength <- read.csv('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/acclimation_strength.csv')
acclimation.strength.nowater <- acclimation.strength.nowater %>% left_join(acclimation.strength[, c(1, 6:7)], by='site_ID')
# # add climate and vegetation classes
# acclimation.strength.nowater <- acclimation.strength.nowater %>% left_join(acclimation[, c('site_ID', 'IGBP', 'Climate_class')], by='site_ID')
# #
plot(acclimation.strength.nowater$r3avg_nw, acclimation.strength.nowater$r3avg, xlim=c(-0.3, 0.05), ylim=c(-0.3, 0.05))
abline(a=0, b=1)
# the sites that have large deviations are: AU-Tum, US-SRG, US-SRM, US-Whs, US-Wkg, ZA-Kru
#
# CA-Ojp ; BE-Vie; CZ-BK1, DE-Hai, FR-Pue, IT-SR2, 
#
# these strengths are highly correlated
write.csv(acclimation.strength.nowater[,c(1:7)], file='/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/acclimation_strength_compare_nowater.csv', row.names=FALSE)
#
t.test(x = acclimation.strength.nowater$r3avg, y = acclimation.strength.nowater$r3avg_nw, paired=T)
#
# Yes, they are strongly different; these without considering water is 0.019 lower than these with water; 
cor.test(acclimation.strength.nowater$r3avg, acclimation.strength.nowater$r3avg_nw)  # R2 = 0.675; (P<0.001)
#
```


```{r combine data and driver analysis}
library(tidyverse)
library(terra)
library(ggpubr)
rm(list=ls())
#
data.dir <- '/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/'
acclimation <- read.csv(file.path(data.dir, "basic_site_info.csv"))
stat.climate       <- read.csv(file.path(data.dir, "climate.csv"))
acclimation$LATabs <- abs(acclimation$LAT)
acclimation        <- acclimation %>% left_join(stat.climate[,1:14], by='site_ID')
# check prec, cor.test = 0.94, not super high. precipitation is highly variable!
# combine with spectral data
data.spectral   <- read.csv(file.path(data.dir, 'spectral.csv'))
acclimation     <- acclimation %>% left_join(data.spectral, by=c('site_ID'='ID'))
#
# combine with stand ages of forests
treeage <- read.csv(file.path(data.dir, 'tree_ages.csv'))
acclimation <- acclimation %>% left_join(treeage, by='site_ID')
# do not use tree age if IGBP is not forest
acclimation$age[!acclimation$IGBP %in% c("MF","ENF","EBF","DBF")] <- NA 

# another source to get stand ages
# standage <- BIF %>% filter(SITE_ID %in% acclimation$site_ID) %>% filter(VARIABLE=='SA' | VARIABLE=='SA_COMMENT') %>% spread(key=VARIABLE, value=DATAVALUE)
#
# combine with soil data
stat.soil       <- read.csv(file.path(data.dir, 'soil.csv'))
acclimation     <- acclimation %>% left_join(stat.soil, by='site_ID')

# add soc_mix and ph_mix; the mix between maps and measurements
acclimation$soc_mix <- acclimation$GSOC_obs
acclimation$soc_mix[is.na(acclimation$GSOC_obs)] <- acclimation$GSOC[is.na(acclimation$GSOC_obs)]
#
acclimation$ph_mix <- acclimation$ph_obs
acclimation$ph_mix[is.na(acclimation$ph_obs)] <- acclimation$phh2o[is.na(acclimation$ph_obs)]
#
# combine with multiple methods to calculate acclimation
acclimation.strength <- read.csv(file.path(data.dir, 'acclimation_strength.csv'))
acclimation     <- acclimation %>% left_join(acclimation.strength, by='site_ID')
#

# do simple analysis
# what explains acclimation strength?
# acclimation$acclimation_significant_level_p
acclimation$significant <- acclimation$r3avg_p < 0.1
ggplot(data=acclimation, aes(x=r3avg, y=abs(LAT), color=IGBP, shape=significant)) +
  geom_point()
#
#  geom_smooth(method = lm)
mean(acclimation$acclimation_strength[acclimation$significant])    # -0.1266593
median(acclimation$acclimation_strength[acclimation$significant])  # -0.097735

# I want to see some trends.
sum(acclimation$significant) / nrow(acclimation)    # 32 % of sites
# first 49 is AmeriFlux, the later 21 is FluxNet; one managed grassland site, do I need to remove it?
#
# combine with monthly temperature increase
# Tmin_month  <- read.csv('/Users/jw2946/Documents/stability_project/progress/Tmin_month.csv')
# acclimation <- acclimation %>% left_join(Tmin_month, by='site_ID')
write.csv(acclimation, file=file.path(data.dir, 'acclimation_data_final.csv'), row.names = F)

```

```{r compare with in-situ experiment and seasonal variations}
# compare with 11 studies which claimed thermal acclimation
rs_field <- read.csv('/Users/jw2946/Documents/stability_project/progress/r3_field.csv')
#
boxplot(rs_field$r3[rs_field$result=='YES'])
boxplot(acclimation$r3avg[acclimation$r3avg_p < 0.1 | acclimation$strgth_p < 0.1])
t.test(rs_field$r3[rs_field$result=='YES'], acclimation$r3avg[acclimation$r3avg_p < 0.1 | acclimation$strgth_p < 0.1])
# t = 0.66565, df = 70.407, p-value = 0.5078  (n = 43)
# means(-0.1154954;  -0.1299097 (ours))
t.test(rs_field$r3[rs_field$result=='YES'], acclimation$r3avg[acclimation$r3avg_p < 0.05])
# t = 0.56588, df = 46.735, p-value = 0.5742
#
df <- data.frame(value = c(acclimation$r3avg, acclimation$r3avg[acclimation$r3avg_p < 0.1 | acclimation$strgth_p < 0.1], 
                           rs_field$r3[rs_field$result=='YES'], 
                           rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='soil'], 
                           rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='leaf']))
df$cat <- c(rep('Our estimated strength', nrow(acclimation)), 
            rep('Our estimated strength (p < 0.1)', length(acclimation$r3avg[acclimation$r3avg_p < 0.1 | acclimation$strgth_p < 0.1])), 
            rep('Significant strength from literature', length(rs_field$r3[rs_field$result=='YES'])),
            rep('Significant strength from literature (soil)', length(rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='soil'])),
            rep('Significant strength from literature (leaf)', length(rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='leaf']))) 
#
ggplot(data=df, aes(x=cat, y=value)) +
  geom_boxplot() +
  labs(x='Category', y='Thermal acclimation strength (1/°C)') +
  theme(axis.text.x = element_text(angle = 15, hjust = 1))
#
# I need to put n value there; p value and significance. 
t.test(rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='soil'], rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='leaf'])
# t = -3.1239, df = 12.509, p-value = 0.008405
t.test(rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='soil'], acclimation$r3avg[acclimation$r3avg_p < 0.1 | acclimation$strgth_p < 0.1])
# t = -1.4686, df = 21.588, p-value = 0.1564
t.test(rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='soil'], acclimation$r3avg[acclimation$r3avg_p < 0.05])
# t = -1.1849, df = 23.735, p-value = 0.2478
#
t.test(rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='leaf'], acclimation$r3avg[acclimation$r3avg_p < 0.1 | acclimation$strgth_p < 0.1])
# t = 2.5756, df = 32.975, p-value = 0.01468
#
t.test(rs_field$r3[rs_field$result=='YES' & rs_field$respiration=='leaf'], acclimation$r3avg[acclimation$r3avg_p < 0.05])
# t = 2.5756, df = 32.975, p-value = 0.01422

```


```{r characteristics of these datasets}
acclimation$lat_category <- cut(acclimation$LAT,
                                breaks=c(-50, 0, 30, 40, 50, 60, 70),
                                labels=c('Southern Heminsphere', '0-30 N', '30-40 N', '40-50 N', '50-60 N', '60-70 N'))
#
acclimation %>% group_by(lat_category) %>% summarise(nSites=n()) %>% ggplot(aes(x=lat_category, y=nSites)) +
  geom_bar(stat="identity", width=0.5)
#
acclimation %>% group_by(Climate_class) %>% summarise(nSites=n()) %>% ggplot(aes(x=Climate_class, y=nSites)) +
  geom_bar(stat="identity", width=0.5)
  
acclimation %>% group_by(IGBP) %>% summarise(nSites=n()) %>% ggplot(aes(x=IGBP, y=nSites)) +
  geom_bar(stat="identity", width=0.5)

# correlation between climate and vegetation class
chisq.test(acclimation$IGBP, acclimation$Climate_class)
# X-squared = 205.12, df = 117, p-value = 8.859e-07
# the two variables are highly correlated. So I just use climate variables. So I only use one of them. 

```

```{r strength of acclimation}
#
ggplot(data=acclimation, aes(x=r3avg, y=abs(LAT), color=IGBP, shape=significant)) +
  geom_point()
#
ggplot(data=acclimation, aes(x=r3avg, y=MAT, color=IGBP, shape=significant)) +
  geom_point()
#
ggplot(data=acclimation, aes(x=r3avg, y=MAP, color=IGBP, shape=significant)) +
  geom_point()
#
ggplot(data=acclimation, aes(x=r3avg, y=ELEV, color=IGBP, shape=significant)) +
  geom_point()
#
ggplot(data=acclimation, aes(x=r3avg, y=Lai, color=IGBP, shape=significant)) +
  geom_point()
#
ggplot(data=acclimation, aes(x=IGBP, y=r3avg)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter()

ggplot(data=acclimation, aes(x=Climate_class, y=r3avg)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter()

t.test(acclimation$r3avg[acclimation$IGBP=='OSH'], acclimation$r3avg[acclimation$IGBP=='GRA'])  # they are not statistically different. 

```

```{r what determines acclimation, check climate and vegetation type, exploration only}
library(car)
summary(lm(data=acclimation, r3avg ~ Climate_class))       # p-value: 0.09074; there is difference among groups
# test normality
res_aov <- aov(r3avg ~ Climate_class, data=acclimation)    # weakly difference among groups
hist(res_aov$residuals)   
shapiro.test(res_aov$residuals)  # p-value = 0.0006872;  not a normal distribution; 
# test if the same variance among groups
leveneTest(r3avg ~ Climate_class, data=acclimation)        # p = 0.3649; no difference in variance
# difference among groups
summary(res_aov)     # p-value: 0.09074; there is difference among groups
###################################################################################
#
summary(lm(data=acclimation, r3avg ~ IGBP))
# OSH (the only one that is significant) > SAV > ENF = DBF > WSA > MF > GRA > WET > EBF
# This order makes lots of sense to me!
summary(aov(r3avg ~ IGBP, data=acclimation))                # no difference among groups, p = 0.221
#
summary(lm(data=acclimation, r3avg ~ Climate_class + IGBP))
#
# 
summary(lm(data=acclimation, r3avg ~ Climate_class + MAT + MAP + NDVI))       # NDVI seems better than EVI, Gpp, and LAI
summary(lm(data=acclimation, r3avg ~ IGBP + MAT + MAP + NEE + ELEV))
summary(lm(data=acclimation, r3avg ~ MAT + MAP + NDVI + ELEV))
# remove IT-Lav
summary(lm(data=acclimation[-70,], r3avg ~ Climate_class + MAT + MAP + NDVI + ELEV))
summary(lm(data=acclimation[-70,], r3avg ~ IGBP + MAT + MAP + NEE))
# 
summary(lm(data=acclimation[-70,], r3avg ~ MAT + MAP))
#
summary(lm(data=acclimation[-70,], r3avg ~ MAT + MAP + ELEV))
#
summary(lm(data=acclimation[-70,], r3avg ~ MAT + MAP+ LATabs)) 
#
summary(lm(data=acclimation[-70,], r3avg ~ ELEV))
#
```


```{r correlation among variables, fig.width=15, fig.height=15}
var.use  <- c("ELEV", "MAP", "MATA", "SSTA", "IATA", "RDTA", "RSTA", "AI", "bdod", "nitrogen", "phh2o", "ph_mix", "sand", "silt", "GSOC", "soc_mix", "Fpar", "EVI", "NDVI", "Lai", "NEE_day", "IGBP", "Climate_class", "r3avg", 'age')
data.cor <- acclimation[, var.use[1:21]]
cor(data.cor)
library(corrplot)
#
testRes = cor.mtest(data.cor, conf.level = 0.99)
#
corrplot(cor(data.cor),
  method = "number",
  p.mat = testRes$p, 
  sig.level = 0.01,
  insig='blank', 
  type = "upper" # show only upper side
)
# ELEV: Fpar, EVI, NDVI, Lai
# MATA: SSTA, IATA, RSTA, phh2o, silt, soc, NEE_day
# MAP: SSTA, RDTA, RSTA, AI, Fpar, EVI, NDVI, Lai, NEE_day
# SSTA: IATA, RDTA, RSTA, bdod, silt, soc, Fpar, NEE_day
# IATA: RSTA, bdod, NEE_day 
# RDTA: AI, bdod, Fpar, EVI, NDVI, Lai, NEE_day
# RSTA: bdod, silt, soc, Fpar, NEE_day
# nitrogen: phh2o, sand, silt
# pH: soc, Fpar, Lai
# sand: silt
# Fpar: "EVI", "NDVI", "Lai", "NEE_day"         ; one of these variables is enough. 
# "EVI": "NDVI", "Lai", "NEE_day"
# "NDVI": "Lai", "NEE_day"
# "Lai": "NEE_day"
#

```


```{r model selection for r3avg}
library(MuMIn)
library(fBasics)
library(car)
library(olsrr)
library(lme4)
#
options(na.action = na.fail)
acclimation.use <- acclimation # %>% filter(!site_ID %in% c('IT-Lav'))  # 
acclimation.use <- acclimation.use[, var.use[c(1:3, 8, 15:22)]]   # remove soil variables 10:14, 
#
model <- lm(r3avg ~ ., data = acclimation.use)   # climate class is strongly correlated to MATA [,-c()]
summary(model)
dredge(model)
summary(lm(r3avg ~ ELEV + NDVI, data = acclimation.use))
#
vif_values <- vif(model)
vif_values
# I need to make a subset too!
sexpr <- expression(!( (NEE && NEE_day) || (MATA && SSTA) || (MATA && RDTA) || (MATA && IATA) || (MATA && soc) || (MATA && phh2o) || (MATA && NEE_day) 
                       || (MAP && SSTA) || (MAP && RDTA) || (MAP && NEE) || (MAP && NEE_day) || (MAP && NEE_night) || (IATA && SSTA) || (soc && SSTA) || (phh2o && SSTA)
                       || (NEE && SSTA) || (NEE_day && SSTA) || (NEE_night && SSTA) || (NEE && RDTA) || (NEE_day && RDTA) || (NEE_night && RDTA) 
                       || (NEE && IATA) || (NEE_day && IATA) || (NEE_night && IATA) || (soc && phh2o) || (nitrogen && phh2o) || (NEE_night && phh2o) 
                       || (NEE_day && NEE) || (NEE_day && NEE_night)))   # these pairs cannot coexist 
# sexpr <- expression(!((MATA && SSTA)))
system.time(dd <- dredge(model, subset = sexpr))
# system.time(dd <- dredge(model))
dd
#
model_simplest <- lm(r3avg ~ Climate_class  + MATA + NEE, data = acclimation.use)
summary(model_simplest)
# the importance of NEE is much smaller than NEE_night; 
hist(model_simplest$residuals)        # the data is normally distributed!
ksnormTest(model_simplest$residuals)  # it is normal distribution, so no worries. 
shapiroTest(model_simplest$residuals)
#
# lmer_model <- lmer(r3avg ~ MATA + NEE + Climate_class + (MATA|Climate_class), data = acclimation.use)
# summary(lmer_model)
# r.squaredGLMM(lmer_model)
# print(ranef(lmer_model))
# print(coef(lmer_model))
#
#
model.use <- lm(r3avg ~ Climate_class + IGBP + MAP + MATA + NEE + NEE_night + nitrogen + soc, data = acclimation.use) # 
summary(model.use)
ols_step_all_possible(model.use)
ols_step_best_subset(model.use)
ols_step_forward_p(model.use)
ols_step_backward_p(model.use)  # only three variables
# we used the best subset selection and the backward stepwise selection method to choose the model with lowest AIC; it only includes climate, temperature, and NEE. linear regression with these variables only to examine how r3 avg vary with them. 

# calculate relative importance of these variables
# relative importance of these variables, including categorical variables?
library(vip)
mod2    <- model.use
newdata <- acclimation.use
# relative importance of the three variables
set.seed(1434) # for reproducibility
#
# permutation-based variable importance
pfun <- function(object, newdata) predict(object, newdata = newdata)
vis <- vi(mod2, method = "permute", target = "r3avg", nsim = 30,
metric = "rmse", pred_wrapper = pfun, train = newdata)
vis$percent <- vis$Importance/sum(abs(vis$Importance))
ggplot(vis, aes(y=percent, x=Variable, fill=Variable)) +
  geom_bar(stat = "identity") +
  coord_flip()
# this is really great! SWC: 0.665; TS: 0.223; GPP: 0.126; This is what I exactly expect. 

# try another method firm method, I need to have a partial plot. 
# Compute variance-based variable importance (VI) scores using a simple feature importance ranking measure (FIRM) approach
vis <- vi_firm(mod2, pred.fun=pfun, train=newdata)               
# vi_firm(mod2, train=df_accurate, var_continuous = stats::mad)   
pdp::partial(mod2, pred.var='r3avg', plot=TRUE, rug=TRUE)   #
#
vis$percent <- vis$Importance/sum(abs(vis$Importance))
ggplot(vis, aes(y=percent, x=Variable, fill=Variable)) +
  geom_bar(stat = "identity") +
  coord_flip()

# SHAP-based variable importance; similar to the firm method. 
library(fastshap)
vis <- vi_shap(mod2, pred_wrapper = pfun, train = newdata, nsim=30)
vip(mod2, method='shap', pred_wrapper = pfun, train = newdata, nsim=30, 
    geom = "point", horizontal = FALSE, aesthetics = list(color = "forestgreen", shape = 17, size = 5))
#
vis$percent <- vis$Importance/sum(abs(vis$Importance))
ggplot(vis, aes(y=percent, x=Variable, fill=Variable)) +
  geom_bar(stat = "identity") +
  coord_flip()

# I will use the first two methods to identify important variables; and then do sensitivity analysis [need to check other studies]. 

```


```{r relationship to environmental variables}
acclimation.use <- acclimation
# MAP
ggplot(data=acclimation.use, aes(x=MAP, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Mean annual precipitation (mm)', y='Acclimation strength')
#
acclimation.use %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%     # , 'Am'
  ggplot(aes(x=MAP, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Mean annual precipitation (mm)', y='Acclimation strength')
#
# MAT:
acclimation.use %>% filter(!Climate_class %in% c('ET')) %>%
  ggplot(aes(x=MATA, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Mean annual temperature (C)', y='Acclimation strength')
#
acclimation.use %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%      #, 'Am'
  ggplot(aes(x=MATA, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Mean annual temperature (C)', y='Acclimation strength')
# code region
acclimation.use %>% filter(Climate_class %in% c('Dfa', 'Dfb', 'Dfc', 'Dfd')) %>%
  ggplot(aes(x=MATA, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Mean annual temperature (C)', y='Acclimation strength')
# temperature region
acclimation.use %>% filter(Climate_class %in% c('Cfa', 'Cfb')) %>%
  ggplot(aes(x=MATA, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Mean annual temperature (C)', y='Acclimation strength')
# I should differentiate grassland and forests, because they have different sequestration potentials. 
#
# elevation
ggplot(data=acclimation, aes(x=ELEV, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Elevation (m)', y='Acclimation strength')
#
# single most important variables
ggplot(data=acclimation, aes(x=LATabs, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Latitude (degree)', y='Acclimation strength')
#

# NEE_day
ggplot(data=acclimation.use, aes(x=NEE_day, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Annual mean day respiration (mol CO2 / m2 / year)', y='Acclimation strength')
#
acclimation.use %>% filter(!Climate_class%in% c('Bsh', 'ET', 'Csa', 'Csb', 'Bwk', 'Bsk'))  %>%  filter(NEE > -1600) %>%     # 
  ggplot(aes(x=NEE_day, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Annual mean day NEE (mol CO2 / m2 / year)', y='Acclimation strength')
# include that site
acclimation.use %>% filter(!Climate_class%in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk'))  %>%
  ggplot(aes(x=NEE_day, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Annual mean day NEE (mol CO2 / m2 / year)', y='Acclimation strength')

# NEE
ggplot(data=acclimation.use, aes(x=NEE, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Annual mean NEE (mol CO2 / m2 / year)', y='Acclimation strength')
#
acclimation.use %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>% filter(NEE > -1600) %>%
  ggplot(aes(x=NEE, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Annual mean NEE (mol CO2 / m2 / year)', y='Acclimation strength')
#
acclimation.use %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%
  ggplot(aes(x=NEE, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Annual mean NEE (mol CO2 / m2 / year)', y='Acclimation strength')

# LAI
ggplot(data=acclimation, aes(x=Lai, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Lai', y='Acclimation strength')
acclimation %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%  # , 'Am'
  ggplot(aes(x=Lai, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='LAI', y='Acclimation strength')

# Gpp
ggplot(data=acclimation, aes(x=Gpp, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Gpp', y='Acclimation strength')
acclimation %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%  # , 'Am'
  ggplot(aes(x=Gpp, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Gpp', y='Acclimation strength')

# EVI
ggplot(data=acclimation, aes(x=EVI, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='EVI', y='Acclimation strength')
acclimation %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%  # , 'Am'
  ggplot(aes(x=EVI, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='EVI', y='Acclimation strength')

# NDVI
ggplot(data=acclimation, aes(x=NDVI, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='NDVI', y='Acclimation strength')
acclimation %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%  # , 'Am'
  ggplot(aes(x=NDVI, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='NDVI', y='Acclimation strength')
#### NDVI is even stronger than LAI

## effect of SOC
acclimation.use %>% filter(!Climate_class %in% c('Bsh', 'Csb', 'ET', 'Csa', 'Bwk', 'Bsk')) %>%      #, 'Am'
  ggplot(aes(x=soc_mix, y=r3avg)) +
  geom_point() +
  geom_smooth(method='lm') +
  stat_cor(color='green') + 
  labs(x='Soil organic carbon content', y='Acclimation strength')

```


```{r random forest model}
library(randomForest)
library(caret)
library(VSURF)
library(car)
# three variables are used for prediction
# separate data into trained or tested
set.seed(222)
# try VSURF
acclimation <- read.csv('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/acclimation_data_final.csv')
# 
acclimation12 <- acclimation[, c("r3avg", "ELEV", "MAP", "MATA", "SSTA", "RDTA", "IATA", "soc_mix", "NDVI", "EVI", "Lai", "Gpp")]  # "soc_mix", "GSOC"
#
# var_selection <- VSURF(r3avg ~ ., data=acclimation12, na.action = na.fail)
# they give me almost the same results: ELEV, EVI (similar as LAI), and pH, that is exactly the order of these variables. but temperature is also so important, and should be incorporated there. 
#
# 
acclimation.use <- acclimation[, c("r3avg", "ELEV", "MATA", "Lai", "soc_mix")]       # "phh2o", ph is not used because it is not reliable, 12/16/2024
# calculate vif of the four predictors
lm_model <- lm(data=acclimation.use, r3avg ~ .)
car::vif(lm_model)
# vif: variance inflation factors
#     ELEV     MATA      Lai  soc_mix 
# 1.254205 1.204899 1.233106 1.175923
#
# stratify the data, and create folds
acclimation$Climate_reclass <- acclimation$Climate_class
acclimation$Climate_reclass[acclimation$Climate_class %in% c("Bwk", "Csa")] <- 'arid_hot_med'
acclimation$Climate_reclass[acclimation$Climate_class %in% c("Bsk", "Bsh", "Csb")] <- 'semi_arid_warm_med'
acclimation$Climate_reclass[acclimation$Climate_class %in% c("Am", "Cfa", "Cfb", "Dfa", "Dfb", "Dfc", "Dfd", "Dwc")] <- 'humid'
# create folds
k_folds <- 5
folds <- createFolds(acclimation$Climate_reclass, k = k_folds, list = TRUE, returnTrain = FALSE)
#
#
# var.use[1:22] , "Lai" , "MAP", "MATA",  # do not incorporate nitrogen because it is hard to justify the highly non-linear results 
data  <- acclimation.use # %>% filter(!is.na(age))  # adding ages also does not make sense to the results
# 
perf = data.frame(RMSE_train=double(), R2_train=double(), MAE_train=double(), RMSE_test=double(), R2_test=double(), MAE_test=double())
for (i in 1:40) {
  print(paste0('nodesize', i))
  y0.train <- c()
  y0.test  <- c()
  yobs.train <- c()
  yobs.test  <- c()
  for (j in 1:k_folds) {
    rf0 <- randomForest(formula = r3avg ~ ., data=data[-folds[[j]], ], do.trace=FALSE, mtry=1, nodesize=i, ntree=500)
    y0  <- predict(rf0, data)    
    y0.train <- c(y0.train, y0[-folds[[j]]])
    y0.test  <- c(y0.test,  y0[folds[[j]]])
    #
    yobs.train <- c(yobs.train, data$r3avg[-folds[[j]]])
    yobs.test  <- c(yobs.test, data$r3avg[folds[[j]]])
  }
  #
  perf[i,1:3] <- postResample(pred=y0.train, obs=yobs.train)
  perf[i,4:6] <- postResample(pred=y0.test,  obs=yobs.test)
}
plot(perf[,1] - perf[,4])
plot(perf[,2] - perf[,5])
plot(perf[,3] - perf[,6])
plot(perf[,4])
plot(perf[,5])
plot(perf[,6])
#
################################################### 
# This is another way to set up cross-validation; but it can only tell the proper mtry. 
train_control <- trainControl(method = "cv",  # Cross-validation
                              number = 5)    # Number of folds
#
set.seed(985)
rf0 <- caret::train(form = r3avg ~ ., data=data, method='rf', trControl = train_control, tuneLength = 5)
print(rf0)
rf0$bestTune
rf0$results

#####the model to use, with bootstrapping
library(rsample)
data_strat <- acclimation[, c("r3avg", "ELEV", "MATA", "Lai", "soc_mix", "Climate_reclass")]
strat_bootstrap <- bootstraps(data_strat, times = 200, strata = "Climate_reclass")
# This also gives the out of bag sampling using: first_oob <- assessment(strat_bootstrap$splits[[1]])
# Access the first bootstrap sample
varImp  <- data.frame(elev=double(), mat=double(), lai=double(), ph=double())
partial <- data.frame(var=character(), x=double(), y025=double(), y050=double(), y=double(), y950=double(), y975=double())
partial[1:51, 1]    <- "elev"
partial[52:102, 1]  <- "mat"
partial[103:153, 1] <- "lai"
partial[154:204, 1] <- "soc"
matrix.boot <- matrix(0, nrow=204, ncol=200)
for (i in 1:200) {
  print(i)
  data_sample <- analysis(strat_bootstrap$splits[[i]])
  data_sample <- data_sample[, 1:5]
  rf <- randomForest(formula = r3avg ~ ., data=data_sample, do.trace=FALSE, mtry=1, nodesize=24, ntree=500, importance=TRUE)   # I have to add importance=TRUE here, to get type 1 RI values!
  Imp_tmp <- importance(rf, type=1, scale=TRUE)[1:4]
  varImp[i, 1:4] <- Imp_tmp / sum(Imp_tmp)
  # type=2: the decrease in node impurity; The node impurity is measured by the Gini index; May have some problems. so I use type I: permutation-based MSE reduction. 
  # partial plot values
  tmp1 <- partialPlot(rf, pred.data=data, x.var="ELEV", plot=FALSE)
  tmp2 <- partialPlot(rf, pred.data=data, x.var="MATA", plot=FALSE)
  tmp3 <- partialPlot(rf, pred.data=data, x.var="Lai", plot=FALSE)
  tmp4 <- partialPlot(rf, pred.data=data, x.var="soc_mix", plot=FALSE)
  if (i == 1) {
    partial[1:51, 2]    <- tmp1$x
    partial[52:102, 2]  <- tmp2$x
    partial[103:153, 2] <- tmp3$x
    partial[154:204, 2] <- tmp4$x
  }
  matrix.boot[1:51, i]    <- tmp1$y
  matrix.boot[52:102, i]  <- tmp2$y
  matrix.boot[103:153, i] <- tmp3$y
  matrix.boot[154:204, i] <- tmp4$y
}
# confidence interval of RI; the three are almost equally important
for (i in 1:4) {
  print(quantile(varImp[,i], c(0.025, 0.05, 0.5, 0.95, 0.975)))
}
#       2.5%        5%       50%       95%     97.5% 
# ele: 0.1886710 0.2129134 0.2940669 0.3742908 0.3956409  (1)
# mat: 0.1453366 0.1549683 0.2172829 0.2881334 0.2987378  (3)
# lai: 0.2187312 0.2311713 0.2988688 0.3824310 0.4117751  (2) 
# soc: 0.1053378 0.1169086 0.1846725 0.2545087 0.2620789  (4)

# confidence interval of bootstrap
for (i in 1:204) {
  partial[i, 3:7] <- quantile(matrix.boot[i,], c(0.025, 0.05, 0.5, 0.95, 0.975))
}
# standarize my x variable
partial$x_norm   <- partial$x
partial$x_norm[1:51] <- scale(partial$x[1:51])
partial$x_norm[52:102] <- scale(partial$x[52:102])
partial$x_norm[103:153] <- scale(partial$x[103:153])
partial$x_norm[154:204] <- scale(partial$x[154:204])
#
write.csv(partial, '/Users/jw2946/Documents/stability_project/manuscripts/plot/partial_plot.csv', row.names = F)
#
#################################################################################################
####the last best model
rf0 <- randomForest(formula = r3avg ~ ., data=data, do.trace=FALSE, mtry=1, nodesize=24, ntree=500, importance=TRUE)
print(rf0)
y0  <- predict(rf0, data) 
print(postResample(pred=y0,  obs=data$r3avg))
#       RMSE   Rsquared        MAE 
# 0.05788558 0.63570658 0.04197571
# out of bag variation explained: 9.27% 
#
partialPlot(rf0, pred.data=data, x.var="ELEV")
partialPlot(rf0, pred.data=data, x.var="Lai")
# partialPlot(rf0, pred.data=data, x.var="MAP")
partialPlot(rf0, pred.data=data, x.var="MATA")
partialPlot(rf0, pred.data=data, x.var="soc_mix")
# partialPlot(rf0, pred.data=data, x.var="soc")
# partialPlot(rf0, pred.data=data, x.var="age")
#
varImpPlot(rf0, sort=TRUE, n.var=min(30, nrow(rf0$importance)),
type=1, class=NULL, scale=TRUE,
main='Relative importance')
#


```


```{r XGBoost, not used because of too nonlinear}
library(Matrix)
library(xgboost)
library(caret)
# three variables are used for prediction
# separate data into trained or tested
# set.seed(222)
# 
acclimation.use <- acclimation[, c("r3avg", "ELEV", "MAP", "MATA", "Lai", "soc", "phh2o")]       # var.use[1:22] , "Lai" , "MAP", "MATA", 
#
# ind <- sample(2, nrow(acclimation.use), replace = TRUE, prob = c(0.7, 0.3))
# train <- as.matrix(acclimation.use[ind==1,])         # solar radiation in and out
# test  <- as.matrix(acclimation.use[ind==2,])
# #
# bstSparse <- xgboost(data = train[,2:7], label = train[,1], max.depth = 5, eta = 0.3, nthread = 2, nrounds = 10)
# use cross-validation directly

data <- acclimation.use
data.sparse = sparse.model.matrix(r3avg~.-1, data)    # -1 means no intercept!
xgb.cv(data = data.sparse, label = data$r3avg, max.depth = 5, eta = 0.3, nthread = 2, nrounds = 100, nfold=5, objective = "reg:squarederror")   # nround = 11 is enough. 
#
bstxgb <- xgboost(data = data.sparse, label = data$r3avg, max.depth = 5, eta = 0.3, nthread = 2, nrounds = 8, objective = "reg:squarederror")
pred <- predict(bstxgb, data.sparse)
postResample(pred=pred, obs=data$r3avg) 
#
importance_matrix <- xgb.importance(model = bstxgb)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
#
library(pdp)
partial(bstxgb, pred.var="ELEV", plot=T, train=data[,-1]) #
partial(bstxgb, pred.var="MAP", plot=T, train=data[,-1]) #
partial(bstxgb, pred.var="MATA", plot=T, train=data[,-1]) #
partial(bstxgb, pred.var="Lai", plot=T, train=data[,-1]) #
#partial(bstxgb, pred.var="NDVI", plot=T, train=data[,-1]) #
partial(bstxgb, pred.var="phh2o", plot=T, train=data[,-1]) #
partial(bstxgb, pred.var="soc", plot=T, train=data[,-1]) #

# I cannot consider the sudden changes, that may be not realistic. 

```


```{r simple code to get monthly change in Tmin for all sites}
library(terra)
  #
  basic_info <- read.csv('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/basic_site_info.csv') # only use coordinates
  xy <- data.frame(x=basic_info$LONG, y=basic_info$LAT)  
  #
  ssps <- c('ssp126', 'ssp245', 'ssp370', 'ssp585')
  for (ssp in ssps) {
    Tmin_change2010_2050 <- terra::rast(paste0('/Users/jw2946/Documents/data/Tmin_change2010_2050_', ssp, '.tif'))  
    #
    icell <- adjacent(Tmin_change2010_2050, cellFromXY(Tmin_change2010_2050, xy), include=TRUE)
    tmp <- terra::extract(Tmin_change2010_2050, c(icell))
    Tmin_month <- data.frame(site_ID=basic_info$site_ID)
    for (i in 1:ncol(tmp)) {
      Tmin_month[,i+1] <- as.vector(tapply(tmp[,i], rep(1:nrow(xy), times=5), mean, na.rm=T))
    }
    colnames(Tmin_month)[2:13] <- paste0('Tmin', 1:12)
    write.csv(Tmin_month, file=paste0('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/Tmin_month_', ssp, '_wc.csv'), row.names=FALSE)
    #
  }

```



```{r get monthly temperature from worldclimate}
dir <- '/Users/jw2946/Documents/data/climate/wc2.1_2.5m_tmin/'
#
files <- list.files(dir)
tasmin <- terra::rast()
for (i in 1:12) {
  if (i < 10) {
    month <- paste0(0, i)
  } else {
    month <- i
  }
  print(month)
  id <- grepl(pattern=paste0(month, '.tif$'), files)
  id[253:264] <- FALSE        # do not use data on 2021
  tasmin <- c(tasmin, terra::app(terra::rast(paste0(dir, files[id])), fun=mean))
}
plot(tasmin)
#
names(tasmin) <- 1:12
# monthly average, put the data somewhere
writeRaster(tasmin, filename = '/Users/jw2946/Documents/data/wc2.1_2.5m_tmin2000-2020_mean.tif', overwrite=T)

```


```{r get monthly air temperature change over 40 years using world climate data, use only once}
library(terra)
#
  data.dir <- '/Users/jw2946/Documents/data/climate/'
  #
#  base_line <- terra::rast(list.files(paste0(data.dir, 'wc2.1_30s_tmin/'), pattern='.tif$', full.names = T))  # this baseline is 1970-2000
  base_line <- terra::rast('/Users/jw2946/Documents/data/wc2.1_2.5m_tmin2000-2020_mean.tif')
  # re-projection according to template
#  template  <- terra::rast('/Users/jw2946/Documents/data/wc2.1_2.5m_tmin_2041-2060/wc2.1_30s_tmin_ACCESS-CM2_ssp245_2041-2060.tif')
#  base_line <- terra::resample(base_line, template[[1]])
  #
  acclimation <- read.csv('/Users/jw2946/Documents/stability_project/progress/acclimation_data_final.csv') # only use coordinates
  xy <- data.frame(x=acclimation$LONG, y=acclimation$LAT)  
  #
  files <- list.files(path='/Users/jw2946/Documents/data/wc2.1_2.5m_tmin_2041-2060', pattern='.tif$', full.names = T)  # 12 future models
  nfiles <- length(files)
  #
  ssps <- c('ssp126', 'ssp245', 'ssp370', 'ssp585')
  for (ssp in ssps) {
    id.select <- grepl(pattern=ssp, files)
    #
    raster_list <- lapply(files[id.select], rast)
    GCM <- list()
    #
    for (i in 1:nlyr(raster_list[[1]])) {
    #  i = 1
      print(i)
      # Extract the layer from each raster
      layers <- lapply(raster_list, function(x) x[[i]])
      
      # Compute the average of layers
      GCM[[i]] <- terra::app(terra::rast(layers), fun=mean)
    }
    #
    GCM <- terra::rast(GCM)
    writeRaster(GCM, file=paste0('/Users/jw2946/Documents/data/GCM2041_2060_', ssp, '.tif'), overwrite=T)    
    #
    Tmin_change2010_2050 <- GCM - base_line
    mean(terra::values(Tmin_change2010_2050[[6]]), na.rm=T)
    #
    writeRaster(Tmin_change2010_2050, file=paste0('/Users/jw2946/Documents/data/Tmin_change2010_2050_', ssp, '.tif'), overwrite=T)   
    #
    icell <- adjacent(Tmin_change2010_2050, cellFromXY(Tmin_change2010_2050, xy), include=TRUE)
    tmp <- terra::extract(Tmin_change2010_2050, c(icell))
    Tmin_month <- data.frame(site_ID=acclimation$site_ID)
    for (i in 1:ncol(tmp)) {
      Tmin_month[,i+1] <- as.vector(tapply(tmp[,i], rep(1:nrow(xy), times=5), mean, na.rm=T))
    }
    colnames(Tmin_month)[2:13] <- paste0('Tmin', 1:12)
    write.csv(Tmin_month, file=paste0('/Users/jw2946/Documents/stability_project/progress/Tmin_month_', ssp, '_wc.csv'), row.names=FALSE)
    #
  }

```


```{r get monthly min temperature in 2000-2019}
# processing data from chesla, but different from world climate; not used. 
dir <- '/Users/jw2946/Documents/data/monthly_tasmin2000-2019/'
#
files <- list.files(dir)
tasmin <- terra::rast()
for (i in 1:12) {
  if (i < 10) {
    month <- paste0(0, i)
  } else {
    month <- i
  }
  print(month)
  id <- grepl(pattern=paste0('tasmin_', month), files)
  tasmin <- c(tasmin, terra::app(terra::rast(paste0(dir, files[id])), fun=mean))
}
tasmin.norm <- tasmin / 10 - 273.15
plot(tasmin.norm)    # this is the unit: K/10
# plot(terra::rast(paste0(dir, files[1])) / 10 - 273.15)
#
names(tasmin.norm) <- 1:12
# monthly average, put the data somewhere
writeRaster(tasmin.norm, filename = '/Users/jw2946/Documents/data/monthly_tasmin2000-2019_mean.tif', overwrite=T)
# 

```


```{r using all the data from chelsa for this calculation}
# It may be interesting to look at different climate scenarios!
# The less climate change, the nature is more likely to compensate climate change; I did not use this one because I want to have the horizon of 2041-2060 (prefer not long enough); 
dir <- '/Users/jw2946/Documents/data/monthly_tasmin2041-2070/'
# 3 scenarios
tasmin126 <- terra::rast()
tasmin370 <- terra::rast()
tasmin585 <- terra::rast()
files <- list.files(dir)
for (i in 1:12) {
  if (i < 10) {
    month <- paste0(0, i)
  } else {
    month <- i
  }
  print(month)
  #
  id <- grepl(pattern=paste0('ssp126_tasmin_', month, '_2041_2070_norm.tif$'), files)
  tasmin126 <- c(tasmin126, terra::app(terra::rast(paste0(dir, files[id])), fun=mean))
  #
  id <- grepl(pattern=paste0('ssp370_tasmin_', month, '_2041_2070_norm.tif$'), files)
  tasmin370 <- c(tasmin370, terra::app(terra::rast(paste0(dir, files[id])), fun=mean))
  #
  id <- grepl(pattern=paste0('ssp585_tasmin_', month, '_2041_2070_norm.tif$'), files)
  tasmin585 <- c(tasmin585, terra::app(terra::rast(paste0(dir, files[id])), fun=mean))  
}
writeRaster(tasmin126, filename = '/Users/jw2946/Documents/data/monthly_tasmin2041-2070_ssp126.tif', overwrite=T)
writeRaster(tasmin370, filename = '/Users/jw2946/Documents/data/monthly_tasmin2041-2070_ssp370.tif', overwrite=T)
writeRaster(tasmin585, filename = '/Users/jw2946/Documents/data/monthly_tasmin2041-2070_ssp585.tif', overwrite=T)

# read baseline climate
baseline <- terra::rast('/Users/jw2946/Documents/data/monthly_tasmin2000-2019_mean.tif')
# temperature change
Tasmin_change2010_2055_ssp126 <- tasmin126 - baseline
Tasmin_change2010_2055_ssp370 <- tasmin370 - baseline
Tasmin_change2010_2055_ssp585 <- tasmin585 - baseline
writeRaster(Tasmin_change2010_2055_ssp126, filename = '/Users/jw2946/Documents/data/monthly_tasmin_change2010_2055_ssp126.tif', overwrite=T)
writeRaster(Tasmin_change2010_2055_ssp370, filename = '/Users/jw2946/Documents/data/monthly_tasmin_change2010_2055_ssp370.tif', overwrite=T)
writeRaster(Tasmin_change2010_2055_ssp585, filename = '/Users/jw2946/Documents/data/monthly_tasmin_change2010_2055_ssp585.tif', overwrite=T)  
#
#################
acclimation <- read.csv('/Users/jw2946/Documents/stability_project/progress/acclimation_data_final.csv') # only use coordinates
xy <- data.frame(x=acclimation$LONG, y=acclimation$LAT)
####three cases
for (j in 1:3) {
  print(j)
  if (j==1) {
    Tmin_change <-Tasmin_change2010_2055_ssp126
  } else if (j==2) {
    Tmin_change <-Tasmin_change2010_2055_ssp370
  } else if (j==3) {
    Tmin_change <-Tasmin_change2010_2055_ssp585
  }
  icell <- adjacent(Tmin_change, cellFromXY(Tmin_change, xy), include=TRUE)
  tmp <- terra::extract(Tmin_change, c(icell))
  Tmin_month <- data.frame(site_ID=acclimation$site_ID)
  for (i in 1:ncol(tmp)) {
    Tmin_month[,i+1] <- as.vector(tapply(tmp[,i], rep(1:nrow(xy), times=5), mean, na.rm=T))
  }
  colnames(Tmin_month)[2:13] <- paste0('Tmin', 1:12)
  if (j==1) {
    write.csv(Tmin_month, file='/Users/jw2946/Documents/stability_project/progress/Tmin_month_ssp126.csv', row.names=FALSE) 
  } else if (j==2) {
    write.csv(Tmin_month, file='/Users/jw2946/Documents/stability_project/progress/Tmin_month_ssp370.csv', row.names=FALSE) 
  } else if (j==3) {
    write.csv(Tmin_month, file='/Users/jw2946/Documents/stability_project/progress/Tmin_month_ssp585.csv', row.names=FALSE) 
  }
}

```


```{r unified method to calculate acclimation in non-growing season}
# only consider the four months with lowest temperature. 

# rm(list=ls())
options(na.action = na.omit)
acclimation.strength.ngrow <- data.frame(site_ID=character(), strgth=double(), strgth_p=double(), 
                                   r3=double(), r3_p=double(), r3avg_ng=double(), r3avg_p=double()) # , r3avg0=double(), r3avg0_p=double()
data_dir <- "/Users/jw2946/Documents/stability_project/RespiarationData/"
files <- list.files(data_dir, pattern='_outcome.RDS', full.names = T) 
for (i in 1:length(files)) {
#  i = 52
  print(i)
  outcome.in <- readRDS(files[i])
  #
  acclimation.strength.ngrow[i, 1] <- outcome.in$site_ID
  tStart   <- outcome.in$tStart
  tEnd     <- outcome.in$tEnd
  NEE_grow <- outcome.in$NEE_grow
  # get average soil temperature of non-growing season; need to read ac data
  ac <- readRDS(paste0(data_dir, outcome.in$site_ID, '_ac.RDS'))
  if (outcome.in$site_ID %in% c('ZA-Kru', 'AU-Tum')) {
    # southern hemisphere, the lowest temperature is 5-8
    NEE_ngrow <- ac %>% filter(YEAR %in% NEE_grow$YEAR) %>% filter(MONTH >=5 & MONTH <= 8) %>% group_by(YEAR) %>% summarise(TA=mean(TA, na.rm=T), TS=mean(TS, na.rm=T))
  } else {
    # northern hemisphere, the lowest temperature is 11-2
    NEE_ngrow <- ac %>% filter(YEAR %in% NEE_grow$YEAR) %>% filter(MONTH %in% c(11, 12, 1, 2)) %>% group_by(YEAR) %>% summarise(TA=mean(TA, na.rm=T), TS=mean(TS, na.rm=T))
  }
  Tset  <- mean(NEE_ngrow$TS)
  tStart <- as.integer(max(Tset * 10 - 10, result_row[1, 1] * 10))
  tEnd   <- as.integer(Tset * 10) + 10
  nyear <- nrow(NEE_ngrow)
  #
  # average respiration over the non-growing season
  result_row <- outcome.in$result
  Ravg_GW    <- colSums(result_row[tStart:tEnd, 2:(nyear+1)]) * 0.1
  Ravg_GW    <- Ravg_GW / mean(Ravg_GW, na.rm=T) 
  #
  # average response ratio over the growing season
  result_row_avg <- rowMeans(result_row[, 2:(nyear+1)], na.rm=T)
  RRavg_GW       <- result_row[tStart:tEnd, 2:(nyear+1)] / result_row_avg[tStart:tEnd]
  RRavg_GW       <- colMeans(RRavg_GW)
  #
  # calculate acclimation strength by three methods
  df <- data.frame(TS=NEE_ngrow$TS, alpha=Ravg_GW, alpha_ln=log(Ravg_GW), alpha_ln_avg=log(RRavg_GW))
  ggplot(df, aes(x=TS, y=alpha_ln)) + 
  geom_point() +
  geom_smooth(method = lm) +
  stat_cor(color='green') +
  labs(x='Mean soil temperature (C)', y='Respiration response ratio')
    acclimation.strength.ngrow[i, 2:3] <- summary(lm(data=df, alpha~TS))$coefficients[2,c(1,4)]
    #
    acclimation.strength.ngrow[i, 4:5] <- summary(lm(data=df, alpha_ln~TS))$coefficients[2,c(1,4)]
    #
    acclimation.strength.ngrow[i, 6:7] <- summary(lm(data=df, alpha_ln_avg~TS))$coefficients[2,c(1,4)]
}

# these strengths are highly correlated
write.csv(acclimation.strength.ngrow, file='/Users/jw2946/Documents/stability_project/progress/acclimation_strength_non_growing.csv', row.names=FALSE)

plot(density(acclimation.strength.ngrow$r3avg))
quantile(acclimation.strength.ngrow$r3avg, prob=c(0, 0.1, 0.25, 0.4, 0.5, 0.6, 0.65, 0.7, 0.75, 0.9, 1))
# 36% of sites show enhancing acclimation; the fraction is much higher. It is still compensatory acclimation dominated. 
#
acclimation.strength.ngrow <- acclimation.strength.ngrow %>% left_join(acclimation[, c('site_ID', 'r3avg')], by='site_ID')
plot(acclimation.strength.ngrow$r3avg.x, acclimation.strength.ngrow$r3avg.y)
# not very correlated. so I am not going to mention this. 

```


```{r annual NEE and temperature relationship}
#
# this is used to check underlying mechanisms
acclimation <- read.csv('/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/acclimation_data_final.csv')
dir.data    <- '/Users/jw2946/Documents/stability_project/RespiarationData/ALL10122024/'
cause_acclimation <- data.frame(site_name = character(), NEE_TS_annual=double(), NEE_TS_annual_p=double(), 
                                NEE_TS_grow=double(), NEE_TS_grow_p=double(), NEEday_TS_grow=double(), 
                                NEEday_TS_grow_p=double(), NEEnight_TS_grow=double(), NEEnight_TS_grow_p=double())
#
isite = 1
for (i in 1:nrow(acclimation)) {
  # if (acclimation$r3avg_p[i] > 0.05) {        # acclimation$acclimation_significant_level_p[i]
  #   next
  # }
  if (acclimation$r3avg[i] > 0.0) {        # acclimation$acclimation_significant_level_p[i]
    next
  }

    name_site <- acclimation$site_ID[i]
    cause_acclimation[isite, 1] <- name_site
    print(name_site)
  #
    ac <- readRDS(paste0(dir.data, name_site, '_ac.RDS'))
  # get good years only
    outcome <- readRDS(paste0(dir.data, name_site, '_outcome.RDS'))
    good_years <- as.integer(colnames(outcome$result)[!is.na(outcome$result[1,])])
    good_years <- good_years[!is.na(good_years)]
  #
  NEE_annual <- ac %>% filter(YEAR %in% good_years) %>% group_by(YEAR) %>% summarise(TA=mean(TA, na.rm=T), TS=mean(TS, na.rm=T), SWC=mean(SWC, na.rm=T), NEE=mean(NEE_uStar_f, na.rm=T)) 
  NEE_grow   <- ac %>% filter(DOY >= outcome$gStart & DOY <= outcome$gEnd) %>% filter(YEAR %in% good_years) %>% group_by(YEAR) %>% summarise(TA=mean(TA, na.rm=T), TS=mean(TS, na.rm=T), SWC=mean(SWC, na.rm=T), NEE=mean(NEE_uStar_f, na.rm=T))
  #
  # during the day and night
  NEE_grow_day   <- ac %>% filter(daytime) %>% filter(DOY >= outcome$gStart & DOY <= outcome$gEnd) %>% filter(YEAR %in% good_years) %>% group_by(YEAR) %>% summarise(NEE=mean(NEE_uStar_f, na.rm=T))
  NEE_grow_night <- ac %>% filter(!daytime) %>% filter(DOY >= outcome$gStart & DOY <= outcome$gEnd) %>% filter(YEAR %in% good_years) %>% group_by(YEAR) %>% summarise(NEE=mean(NEE_uStar_f, na.rm=T))
  #
  cause_acclimation[isite, 2] <- as.numeric(cor.test(-NEE_annual$NEE, NEE_annual$TS)$estimate)
  cause_acclimation[isite, 3] <- as.numeric(cor.test(-NEE_annual$NEE, NEE_annual$TS)$p.value)
  #
  cause_acclimation[isite, 4] <- as.numeric(cor.test(-NEE_grow$NEE, NEE_grow$TS)$estimate)
  cause_acclimation[isite, 5] <- as.numeric(cor.test(-NEE_grow$NEE, NEE_grow$TS)$p.value)
  #
  cause_acclimation[isite, 6] <- as.numeric(cor.test(-NEE_grow_day$NEE, NEE_grow$TS)$estimate)
  cause_acclimation[isite, 7] <- as.numeric(cor.test(-NEE_grow_day$NEE, NEE_grow$TS)$p.value)
  #
  cause_acclimation[isite, 8] <- as.numeric(cor.test(-NEE_grow_night$NEE, NEE_grow$TS)$estimate)
  cause_acclimation[isite, 9] <- as.numeric(cor.test(-NEE_grow_night$NEE, NEE_grow$TS)$p.value)
  #
  isite = isite + 1
}

# Significant negative correlation occurs: US-SRM, US-MMS, ZA-Kru, US-NR1, US-Whs, US-Oho
hist(cause_acclimation$NEEday_TS_grow)
plot(density(cause_acclimation$NEEday_TS_grow))
mean(cause_acclimation$NEEday_TS_grow)     ###-0.09513156

# no significant positive relationship between NEEday and TS_grow for enhancing TA; p>0.14. 
# for compensating acclimation: except the sites where respiration is limited by water and controling for water removed apparent components;  
# 11 have negative relationship between NEEday and TS_grow; three sites in semi-arid (US-SRM, US-Whs, ZA-Ku), 3 more at other sites (US-MMS, DE-Hai, IT-SR2, dTAS > 0.04) where respiration may be limited by water; confounding effects were controlled by incorporating soil water in respiration models. The rest 5: US-NR1, US-Oho, CA-TP3, US-Wrc, ES_Lju.  
##

write.csv(cause_acclimation, '/Users/jw2946/Documents/stability_project/code_acclimation/driver_analysis/cause_acclimation.csv')

```



